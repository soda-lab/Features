{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeoName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz\n",
    "import unidecode\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "flag = config['DEFAULT']['Flag']\n",
    "input_folder = config['DEFAULT']['Input-Folder']\n",
    "prefix = config['DEFAULT']['Prefix']\n",
    "ratio_value = config['DEFAULT']['Ratio-Value']\n",
    "column_number = config['DEFAULT']['Column-Number']\n",
    "output_file = config['DEFAULT']['Output-File']\n",
    "world_cities_file = config['DEFAULT']['World-Cities-File']\n",
    "world_states_file = config['DEFAULT']['World-States-File']\n",
    "world_countries_file = config['DEFAULT']['World-Countries-File']\n",
    "au_cities_file = config['DEFAULT']['AU-Cities-File']\n",
    "au_states_file = config['DEFAULT']['AU-States-File']\n",
    "au_countries_file = config['DEFAULT']['AU-Countries-File']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_city_file(city_file):\n",
    "    cities = pandas.read_csv(city_file, header=0, encoding=\"UTF-8\")\n",
    "    city_list = cities[\"city\"].tolist()\n",
    "    city_state_list = cities[\"state\"].tolist()\n",
    "    city_country_list = cities[\"country\"].tolist()\n",
    "\n",
    "    city_list = [unidecode.unidecode(str(x)) for x in city_list]\n",
    "    city_gid_list = cities[\"geonameid\"].tolist()\n",
    "    \n",
    "    return city_list,city_state_list,city_country_list,city_gid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_state_file(state_file):\n",
    "    states = pandas.read_csv(state_file, header=0, encoding=\"UTF-8\")\n",
    "    state_list = states[\"state\"].tolist()\n",
    "    state_country_list = states[\"country\"].tolist()\n",
    "\n",
    "    state_list = [unidecode.unidecode(str(x)) for x in state_list]\n",
    "    state_gid_list = states[\"geonameid\"].tolist()\n",
    "    \n",
    "    return state_list,state_country_list,state_gid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_country_file(country_file):\n",
    "    countries = pandas.read_csv(country_file, header=0, encoding=\"UTF-8\")\n",
    "    country_list = countries[\"country\"].tolist()\n",
    "\n",
    "    country_list = [unidecode.unidecode(str(x)) for x in country_list]\n",
    "    country_gid_list = countries[\"geonameid\"].tolist()\n",
    "    \n",
    "    return country_list,country_gid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_result(i,city_list,state_list,country_list,fuzz_scorer):\n",
    "    result_list = []\n",
    "    \n",
    "    # delete non-ASCII Characters\n",
    "    uni_i = unidecode.unidecode(str(i))\n",
    "    \n",
    "    # ignore empty string and string only contains special characters\n",
    "    if (not re.match(r'^[_\\W]+$', uni_i)) and (uni_i != \"\"): \n",
    "        # calculate ratio\n",
    "        ci_result = process.extractOne(uni_i,city_list,scorer=fuzz_scorer)\n",
    "        st_result = process.extractOne(uni_i,state_list,scorer=fuzz_scorer)\n",
    "        co_result = process.extractOne(uni_i,country_list,scorer=fuzz_scorer)\n",
    "\n",
    "        result_list.append(ci_result)\n",
    "        result_list.append(st_result)\n",
    "        result_list.append(co_result)\n",
    "\n",
    "        # choose the result with highest ratio\n",
    "        max_result = max(result_list, key=lambda x:x[1])\n",
    "    else:\n",
    "        max_result = ci_result = st_result = co_result = (\"\",0)\n",
    "    \n",
    "    return max_result,ci_result,st_result,co_result,result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get geo information for each value in the list \"user_location\"\n",
    "def get_geo_info(i):\n",
    "    \n",
    "    city = state = country = geonameid = \"\"\n",
    "    city_list = file_dict[\"city\"][geo][\"city\"]\n",
    "    state_list = file_dict[\"state\"][geo][\"state\"]\n",
    "    country_list = file_dict[\"country\"][geo][\"country\"]\n",
    "\n",
    "    max_result,ci_result,st_result,co_result,result_list = get_max_result(str(i),city_list,state_list,country_list,fuzz.token_set_ratio)\n",
    "\n",
    "    # match relevant geoname information\n",
    "    if max_result[1] >= int(ratio_value):\n",
    "        # check if there are multiple max vlaues\n",
    "        max_list = [i for i in result_list if max_result[1] == i[1]]\n",
    "        if len(max_list) > 1:\n",
    "            max_result,ci_result,st_result,co_result,result_list = get_max_result(i,city_list,state_list,country_list,fuzz.token_sort_ratio)\n",
    "           \n",
    "        if max_result == ci_result:  \n",
    "            city = ci_result[0]\n",
    "            index = city_list.index(city)\n",
    "            state = file_dict[\"city\"][geo][\"state\"][index]\n",
    "            country = file_dict[\"city\"][geo][\"country\"][index]\n",
    "            geonameid = file_dict[\"city\"][geo][\"geonameid\"][index]\n",
    "\n",
    "        elif max_result == st_result:\n",
    "            state = st_result[0]\n",
    "            index = state_list.index(state)\n",
    "            country = file_dict[\"state\"][geo][\"country\"][index]\n",
    "            geonameid = file_dict[\"state\"][geo][\"geonameid\"][index]\n",
    "\n",
    "        elif max_result == co_result:\n",
    "            country = co_result[0]\n",
    "            index = country_list.index(country)\n",
    "            geonameid = file_dict[\"country\"][geo][\"geonameid\"][index]\n",
    "\n",
    "    output_list=[str(i), str(city), str(state),str(country),str(geonameid)]\n",
    "    \n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read \"world\" CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read world-cities\n",
    "world_city_list,world_city_state_list,world_city_country_list,world_city_gid_list = read_city_file(world_cities_file)\n",
    "\n",
    "# read world-states\n",
    "world_state_list,world_state_country_list,world_state_gid_list = read_state_file(world_states_file)\n",
    "\n",
    "# read world-countries\n",
    "world_country_list,world_country_gid_list = read_country_file(world_countries_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read \"Australia\" CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read au-cities\n",
    "au_city_list,au_city_state_list,au_city_country_list,au_city_gid_list = read_city_file(au_cities_file)\n",
    "\n",
    "# read au-states\n",
    "au_state_list,au_state_country_list,au_state_gid_list = read_state_file(au_states_file)\n",
    "\n",
    "# read au-country\n",
    "au_country_list,au_country_gid_list = read_country_file(au_countries_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Collection Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_location = []\n",
    "for file in glob.glob(\"{}/{}*.csv\".format(input_folder,prefix)):\n",
    "    data = pandas.read_csv(file, encoding=\"UTF-8\")\n",
    "    user_location = data.iloc[:,int(column_number)].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create file list dictionary\n",
    "file_dict = {\"city\":{\"au\":{\"city\":au_city_list,\n",
    "                          \"state\":au_city_state_list,\n",
    "                          \"country\":au_city_country_list,\n",
    "                          \"geonameid\":au_city_gid_list},\n",
    "                    \"world\":{\"city\":world_city_list,\n",
    "                          \"state\":world_city_state_list,\n",
    "                          \"country\":world_city_country_list,\n",
    "                          \"geonameid\":world_city_gid_list}\n",
    "                    },\n",
    "            \"state\":{\"au\":{\"state\":au_state_list,\n",
    "                          \"country\":au_state_country_list,\n",
    "                          \"geonameid\":au_state_gid_list},\n",
    "                    \"world\":{\"state\":world_state_list,\n",
    "                          \"country\":world_state_country_list,\n",
    "                          \"geonameid\":world_state_gid_list}\n",
    "                    },\n",
    "            \"country\":{\"au\":{\"country\":au_country_list,\n",
    "                            \"geonameid\":au_country_gid_list},\n",
    "                      \"world\":{\"country\":world_country_list,\n",
    "                            \"geonameid\":world_country_gid_list}\n",
    "                      }\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check flag\n",
    "# World\n",
    "if flag == \"1\":\n",
    "    geo = \"world\"\n",
    "    \n",
    "# Australia\n",
    "elif flag == \"2\":\n",
    "    geo = \"au\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiprocessing\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "if len(user_location) > 0 :\n",
    "    cpu_number = os.cpu_count()-3\n",
    "    print(\"Number of using CPU: \" + str(cpu_number))\n",
    "    pool = Pool(processes=cpu_number)   \n",
    "    output_list = pool.map(get_geo_info,user_location)\n",
    "\n",
    "    # write into csv file\n",
    "    df_output = pandas.DataFrame(output_list,columns=['user_location','geoname_city','geoname_state','geoname_country','geoname_id'])\n",
    "    df_output.to_csv(output_file, sep=',',index = False, encoding='UTF-8')\n",
    "else:\n",
    "    print(\"No relevant file found\")\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time used: \"+ str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
