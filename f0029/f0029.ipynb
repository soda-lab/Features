{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import urllib "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "Host_IP = config['DEFAULT']['IP']\n",
    "MongoDB_Port = config['DEFAULT']['MongoDB-Port']\n",
    "DB_Name = config['DEFAULT']['DB-Name']\n",
    "User_Name = config['DEFAULT']['User-Name']\n",
    "Psword = config['DEFAULT']['Psword']\n",
    "Collection_Name = config['DEFAULT']['Collection-Name']\n",
    "Import_Option_File = config['DEFAULT']['Import-Option-File']\n",
    "population_output = config['DEFAULT']['Output-Population-File']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Collections from MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_mongo(host, port, DB_Name, username, password):\n",
    "    \"\"\" A util for making a connection to mongo \"\"\"\n",
    "    client = MongoClient(\"mongodb://{}:{}@{}:{}\".format(username, password, host, 27017))\n",
    "    db = client[DB_Name]\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_extract_collection_names(import_option_df, db):\n",
    "    \"\"\" read \"import_options2016\" text file and identify list of files for downloading data \"\"\"\n",
    "    files = []\n",
    "    for t in import_option_df['Table Number'].tolist():\n",
    "        for table_name in db.list_collection_names():\n",
    "            if t in table_name and table_name.split('_')[-1] == 'SA1':\n",
    "                files.append(table_name)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_collections(import_option_df, DB_Name, Host_IP, MongoDB_Port, username, password):\n",
    "    \"\"\" \n",
    "        Read from \"import_options2016\" text file to identify list of collection for data extraction\n",
    "        and save the extracted collections as dictionary (key:name of collection, value: dataframe)       \n",
    "    \"\"\"\n",
    "    # Connect to MongoDB\n",
    "    census_db = connect_mongo(Host_IP, MongoDB_Port, DB_Name, username, password)\n",
    "    collections = identify_extract_collection_names(import_option_df, census_db)   \n",
    "    # create a dictionary to store DFs\n",
    "    collection_dictionary = {}\n",
    "    for c in collections:\n",
    "        cursor = census_db[c].find()\n",
    "        df =  pd.DataFrame(list(cursor))\n",
    "        collection_dictionary[c] = df\n",
    "    return collection_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_option_df = pd.read_csv('{}.txt'.format(Import_Option_File), delimiter = \",\", comment='#')\n",
    "username = urllib.parse.quote_plus(User_Name)\n",
    "password = urllib.parse.quote_plus(Psword)\n",
    "collection_dictionary = extract_collections(import_option_df, DB_Name, Host_IP, MongoDB_Port, username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DF that store list of collection's name for population data extraction\n",
    "pop_files_df = pd.DataFrame(columns = ['Table Number'])\n",
    "pop_files_df = pop_files_df.append({'Table Number':'2016Census_G01_AUS_SA1'}, ignore_index=True)\n",
    "pop_files_df = pop_files_df.append({'Table Number':'2016Census_G33_AUS_SA1'}, ignore_index=True)\n",
    "pop_files_df = pop_files_df.append({'Table Number':'2016Census_G16B_AUS_SA1'}, ignore_index=True)\n",
    "\n",
    "# download population data (collections)\n",
    "pop_collection_dictionary = extract_collections(pop_files_df, DB_Name, Host_IP, MongoDB_Port, username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Columns In The Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_columns(import_option_df, collection_dictionary):\n",
    "    \"\"\" extract columns from DFs \"\"\"\n",
    "    extracted_collection_dictionary = {}\n",
    "    for index, row in import_option_df.iterrows():\n",
    "        for table in collection_dictionary.keys():\n",
    "            if row['Table Number'] in table:\n",
    "                extracted_collection_dictionary[table] = collection_dictionary[table].filter(regex = row['Regex'].replace(\"'\", \"\"))\n",
    "                extracted_collection_dictionary[table]['SA1_7DIGITCODE_2016'] = collection_dictionary[table]['SA1_7DIGITCODE_2016']\n",
    "    return extracted_collection_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_collection_dictionary = extract_columns(import_option_df, collection_dictionary)\n",
    "# save collections as csv files\n",
    "for df in extracted_collection_dictionary.keys():\n",
    "    extracted_collection_dictionary[df].to_csv(\"{}.csv\".format(df), sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new DF to store total population, total household, and total people aged over 15\n",
    "SA1_code = 'SA1_7DIGITCODE_2016'\n",
    "new_pop_df = pd.DataFrame(columns = [SA1_code])\n",
    "new_pop_df[SA1_code] = pop_collection_dictionary['2016Census_G01_AUS_SA1'][SA1_code]\n",
    "new_pop_df = pd.merge(new_pop_df, pop_collection_dictionary['2016Census_G01_AUS_SA1'][[SA1_code, 'Tot_P_P']], on='SA1_7DIGITCODE_2016')\n",
    "new_pop_df = pd.merge(new_pop_df, pop_collection_dictionary['2016Census_G33_AUS_SA1'][[SA1_code, 'Total_Total']], on='SA1_7DIGITCODE_2016')\n",
    "new_pop_df = pd.merge(new_pop_df, pop_collection_dictionary['2016Census_G16B_AUS_SA1'][[SA1_code, 'P_Tot_Tot']], on='SA1_7DIGITCODE_2016')\n",
    "# rename columns as same as \"Aggregate\" in \"import_options2016.txt\"\n",
    "new_pop_df.rename(columns = {'Tot_P_P':'pops', 'Total_Total':'hhs', 'P_Tot_Tot':'p15'}, inplace=True)\n",
    "# save the population dataframe as csv file\n",
    "new_pop_df.to_csv('{}.csv'.format(population_output), sep=',', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
